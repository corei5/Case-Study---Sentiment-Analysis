{
  "cells": [
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "7ee1a65e-8e3d-43bd-858f-aff0a89bfb50",
        "_uuid": "1246bd8e1ff5878719de53da70cdce3cc6a59d13",
        "trusted": false
      },
      "cell_type": "code",
      "source": "import nltk\nimport re\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nenglish_stemmer=nltk.stem.SnowballStemmer('english')\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "a89efd65-64e6-4480-98ea-af6b796d712a",
        "_uuid": "a816b27f829ea9945347accc544af69833970388",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def review_to_wordlist( review, remove_stopwords=True):\n    # 1. Remove HTML\n    review_text = BeautifulSoup(review).get_text()\n\n    # 2. Remove non-letters\n    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n\n    # 3. Convert words to lower case and split them\n    words = review_text.lower().split()\n    \n    # 4. Optionally remove stop words (True by default)\n    if remove_stopwords:\n        stops = set(stopwords.words(\"english\"))\n        words = [w for w in words if not w in stops]\n\n    b=[]\n    stemmer = english_stemmer #PorterStemmer()\n    for word in words:\n        b.append(stemmer.stem(word))\n\n    # 5. Return a list of words\n    return(b)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "dd2c7b53-8b07-4209-af27-d84698cf08ad",
        "_uuid": "ec9a1cd8bcd94c0e1844be0d77530bc0dfb853a6",
        "trusted": false
      },
      "cell_type": "code",
      "source": "data_file = '../input/Amazon_Unlocked_Mobile.csv'\n\nn = 413000  \ns = 20000 \nskip = sorted(random.sample(range(1,n),n-s))\n\n\ndf = pd.read_csv( data_file, delimiter = \",\", skiprows = skip)\n#print(df)\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "c3654543-5496-408c-bd37-0d47f2bee60d",
        "_uuid": "0a89d7acae7b1869f43543f283d7a41e3234c609",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Drop missing values\ndf.dropna(inplace=True)\n# Remove any 'neutral' ratings equal to 3\ndf = df[df['Rating'] != 3]\n# Encode 4s and 5s as 1 (rated positively)\n# Encode 1s and 2s as 0 (rated poorly)\ndf['Positively Rated'] = np.where(df['Rating'] > 3, 1, 0)\ndf.head(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "055e7edb-547b-414b-aecf-b422750abb54",
        "_uuid": "f12f706a9ab064e7dd3f0c7714308dc23c094c21",
        "trusted": false
      },
      "cell_type": "code",
      "source": "print(len(df['Positively Rated']))\n#df['Reviews']\n\n#for i in range(0,len(df['Positively Rated'])-1,1):\n    #review_to_wordlist(df['Positively Rated'][i])\n# Most ratings are positive\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "4cbd319e-39e4-4388-8d1d-13150744122b",
        "_uuid": "487ed49ac7d5e62378f17f721ac34f0d071665f9",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#data = df[df['Rating'].isnull()==False]\ndf['Positively Rated'].mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "1ad0fd37-d487-45cb-9ecd-3cefb507fe80",
        "_uuid": "2d1889e573468a85d4db41d95dd299473d0e1702",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#train, test = train_test_split(data, test_size = 0.3)\n#X_train, X_test, y_train, y_test = train_test_split(df['Rating'], df['Positively Rated'], random_state=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "a3ff372a-48a8-42de-8672-175941dffd14",
        "_uuid": "43a9eb1659287b52b338683e87ce29e9845417b1",
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "4479c96c-4fb8-41a3-80eb-26f1b3ce4fed",
        "_uuid": "50e687a138a0ca440606d51f7a80bfddb4514838",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Split data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(df['Reviews'], df['Positively Rated'], random_state=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "4cd29d56-2cf5-442f-9498-157f09949756",
        "_uuid": "f62b4f2ae4968f31fdd8261c8b8f4c3bbb958ae0",
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "895dd55c-9ea9-47b8-b5c9-5fe67152f702",
        "_uuid": "24683483d7df341f345c9d96f228ef460a2d9af3",
        "trusted": false
      },
      "cell_type": "code",
      "source": "print('X_train first entry:\\n\\n', X_train.iloc[0])\nprint('\\n\\nX_train shape: ', X_train.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "215a76eb-299c-4265-a1ef-70011283b49e",
        "_uuid": "ba95ec6f4511a28e9aae0fcf9428339b3fe8fd31",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Fit the CountVectorizer to the training data\n\nvect = CountVectorizer().fit(X_train)\n#print(vect)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "8a4ea001-2e51-4c47-852d-5fddc548170a",
        "_uuid": "245c9f624635afec2c117c90b16b0fea6fcadfdb",
        "scrolled": false,
        "trusted": false
      },
      "cell_type": "code",
      "source": "\nvect.get_feature_names()[::2000]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "2948c649-a043-49fb-a6f4-75a13b52d994",
        "_uuid": "fb53f3122baeb9941553aa121f7f6d38c04a7508",
        "trusted": false
      },
      "cell_type": "code",
      "source": "\n#print(vect.get_feature_names()[0])\n#print(len(vect.get_feature_names()))\nfor i in range(0,len(vect.get_feature_names())-1,1):\n    if vect.get_feature_names()[i].isalpha and len(vect.get_feature_names()[i])>2:\n        #if remove_stopwords==True:\n         #   stops = set(stopwords.words(\"english\"))\n          #  words = [w for w in words if not w in stops]\n        #[x.lower() for x in vect.get_feature_names()]\n        vect.get_feature_names()\n#vect.get_feature_names()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "b5a2774f-2db4-43a8-a85b-05dac063d07d",
        "_uuid": "059e2110543baf2c48aa9751a7db524e44c84537",
        "trusted": false
      },
      "cell_type": "code",
      "source": "vect.get_feature_names()[::2000]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "7c56831c-a469-45f0-85cf-0f8dfd34e4ed",
        "_uuid": "65e3b45d54d39b5d08704e11410e7580b2b89133",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# transform the documents in the training data to a document-term matrix\nX_train_vectorized = vect.transform(X_train)\n\nX_train_vectorized",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "0b6747e1-dfb7-4daf-a0b1-5007c9f22b31",
        "_uuid": "b3cde5c2569f00ef6130ef36063c67d39459cac8",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#data.reshape((999,1))\n# Train the model\n#X = X_train_vectorized.reshape(X_train_vectorized.shape[1:])\nmodel = LogisticRegression()\nmodel.fit(X_train_vectorized, y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "93980f70-61a9-44ca-a5f6-5e7caa16e12a",
        "_uuid": "2e844e5c8879b8ac4772c64a9ea451867f32adbd",
        "trusted": false
      },
      "cell_type": "code",
      "source": " #Predict the transformed test documents\npredictions = model.predict(vect.transform(X_test))\n\nprint('AUC: ', roc_auc_score(y_test, predictions))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "a974de98-54f5-4c8e-8193-712580009e12",
        "_uuid": "c7941581ac451919cdb6ca526c8cb5b42be2189d",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# get the feature names as numpy array\nfeature_names = np.array(vect.get_feature_names())\n\n# Sort the coefficients from the model\nsorted_coef_index = model.coef_[0].argsort()\n\n# Find the 10 smallest and 10 largest coefficients\n# The 10 largest coefficients are being indexed using [:-11:-1] \n# so the list returned is in order of largest to smallest\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "7072fbe9-bc03-4439-97a7-7ebb1509efee",
        "_uuid": "647cac945855f6daa71f9ddcfb65a7b166d7b289",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\nfor i in range(0,len(vect.get_feature_names())-1,1):\n    if vect.get_feature_names()[i].isalpha:\n        vect = TfidfVectorizer(min_df=5).fit(X_train)\n        #len(vect.get_feature_names())\n        vect.get_feature_names()\n        #[x.lower() for x in vect.get_feature_names()]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "9761f426-d13a-4cb7-9fbe-a99c3c2530cf",
        "_uuid": "b08d4c80c61a2a565037ee8c26cf8598ff1d2433",
        "trusted": false
      },
      "cell_type": "code",
      "source": "X_train_vectorized = vect.transform(X_train)\n\nmodel = LogisticRegression()\nmodel.fit(X_train_vectorized, y_train)\n\npredictions = model.predict(vect.transform(X_test))\n\nprint('AUC: ', roc_auc_score(y_test, predictions))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "2546dc09-842c-480f-b66e-118b87f047e4",
        "_uuid": "e28c572d2f22232132f31713420f80e47433f383",
        "trusted": false
      },
      "cell_type": "code",
      "source": "feature_names = np.array(vect.get_feature_names())\n\nsorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n\nprint('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\nprint('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-11:-1]]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "11a8e8f4-cf38-4ce8-b479-3c49315e15a8",
        "_uuid": "2ac8267cb82a4d609a7830adc6fcad1300d2ec0d",
        "trusted": false
      },
      "cell_type": "code",
      "source": "sorted_coef_index = model.coef_[0].argsort()\n\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "825b4acf-bac1-48a9-9130-75380f3d3904",
        "_uuid": "b07cac6abd4fbd930c40bc32718e780ea3bb9b0b",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# These reviews are treated the same by our current model\nprint(model.predict(vect.transform(['not an issue, phone is working',\n                                    'an issue, phone is not working'])))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "0d8ae84c-f4f3-45d2-baff-7cf38b1d49fa",
        "_uuid": "33f74163a8eb0b7420224569de55c2ef98e0d96e",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Fit the CountVectorizer to the training data specifiying a minimum \n# document frequency of 5 and extracting 1-grams and 2-grams\nvect = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n\nX_train_vectorized = vect.transform(X_train)\n\nlen(vect.get_feature_names())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "d28dddf5-5b04-4801-82eb-34670042116f",
        "_uuid": "3aa12c3dc8f40d0c13fc30dca9fa751276e85f2e",
        "trusted": false
      },
      "cell_type": "code",
      "source": "model = LogisticRegression()\nmodel.fit(X_train_vectorized, y_train)\n\npredictions = model.predict(vect.transform(X_test))\n\nprint('AUC: ', roc_auc_score(y_test, predictions))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "e819c4db-732b-459a-990f-a4b115d0ab16",
        "_uuid": "fcdf2866e89f77ef1b8a653aa4dcf8427752c364",
        "trusted": false
      },
      "cell_type": "code",
      "source": "feature_names = np.array(vect.get_feature_names())\n\nsorted_coef_index = model.coef_[0].argsort()\n\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "9c04770b-9902-420a-840e-4f59c175aa77",
        "_uuid": "29a827af7abd3c148c1657a31af1c5b117ed81a0",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# These reviews are now correctly identified\nprint(model.predict(vect.transform(['not an issue, phone is working',\n                                    'an issue, phone is not working'])))",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}